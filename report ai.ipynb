{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f0fc24",
   "metadata": {},
   "source": [
    "# 1. Importing Required Libraries\n",
    "\n",
    "Files (os, requests),\n",
    "Text processing (langchain, PyMuPDFLoader, TextLoader),\n",
    "Machine learning (ChatOpenAI, HuggingFaceEmbeddings),\n",
    "Storing and searching embeddings (Chroma, chromadb),\n",
    "Data processing (pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5722fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf8edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e347b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2893984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bcb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190c7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5ad196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c09c039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72dc0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d4da2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4f8f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4236400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72471830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5f9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_conversions import ppt_to_pdf, docx_to_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c271348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\n",
    "    \"OPENAI_API_KEY\"] = \"key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff4b09",
   "metadata": {},
   "source": [
    "# 2. Class Defining ; Final\n",
    "This class contains methods for handling document uploads, text processing, embedding creation, and question-answering.\n",
    "\n",
    "Class Initialization (__init__ method)\n",
    "Loads HuggingFaceEmbeddings to convert text into numerical vectors.\n",
    "Defines paths for storing temporary files and embeddings.\n",
    "Initializes placeholders for different components (retriever, QA model, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf9fb4",
   "metadata": {},
   "source": [
    "Key Variables:\n",
    "self.emb: Path where numeric vectors are stored through embedding.\n",
    "\n",
    "self.temp_pdf_path: Path where temporary PDFs are saved.\n",
    "\n",
    "self.agent_avail: Tracks if the document is CSV/Excel for data querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99b37fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Final:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "                                                model_kwargs={\"device\": \"cuda\"},\n",
    "                                                # model_kwargs={\"device\": \"cpu\"},\n",
    "                                                encode_kwargs={'normalize_embeddings': True})\n",
    "        self.retriever = None\n",
    "        # path to be server can't change\n",
    "        self.emb = f\"/home/ubuntu/Embeddings\"\n",
    "        self.temp_pdf_path = \"/home/ubuntu/temp\"\n",
    "        # path set locally can be edited\n",
    "        # self.emb = \"/home/banshee/Prudentbit/Embeddings\"\n",
    "        self.qa = None\n",
    "        self.em = None\n",
    "        self.source = None\n",
    "        self.persistent_client = None\n",
    "        self.agent = None\n",
    "        self.agent_avail = False\n",
    "        self.df = None\n",
    "        self.page = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20bcd9",
   "metadata": {},
   "source": [
    "Uses HuggingFaceEmbeddings with the model \"sentence-transformers/all-mpnet-base-v2\".\n",
    "Embeddings are normalized (encode_kwargs={'normalize_embeddings': True}).\n",
    "\n",
    "self.emb = \"/home/ubuntu/Embeddings\" . it fixed path on a server.\n",
    "self.temp_pdf_path = \"/home/ubuntu/temp\". it is atemporary storage for PDFs.\n",
    "\n",
    "self.retriever: it store a retriever object for searching embeddings.\n",
    "\n",
    "self.qa:it used for answering questions based on embeddings.\n",
    "\n",
    "self.agent:it is an AI chatbot.\n",
    "\n",
    "self.agent_avail = False: the agent is inactive.\n",
    "\n",
    "self.df:it store metadata, documents, or QA results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b869178b",
   "metadata": {},
   "source": [
    "# 3. check_file_path(self, name)\n",
    "Simply extracts and returns the file extension (e.g., .pdf, .txt, .csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88524cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    " def check_file_path(self, name):\n",
    "        return name.split('.')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba0888",
   "metadata": {},
   "source": [
    "# 4. file_loader(self, path, name, hash=None, domain=None)\n",
    "file_loader is designed to load different file types, extract their content, and process it.\n",
    "Working:\n",
    "Checks the file extension (pdf, docx, pptx, txt, csv, xlsx).\n",
    "Uses different loaders depending on the file type:\n",
    "\n",
    "PDF: Extracts text and images using PyMuPDFLoader.\n",
    "\n",
    "DOCX/DOC: Converts to PDF first, then extracts text.\n",
    "\n",
    "PPTX/PPT: Converts slides to PDF, then extracts text.\n",
    "\n",
    "TXT: Downloads text from a URL and saves it temporarily.\n",
    "\n",
    "CSV/XLSX: Loads into a Pandas DataFrame for structured querying.\n",
    "\n",
    "Stores and organizes files in a directory.\n",
    "\n",
    "If a CSV/XLSX , it sets self.agent_avail = True, allowing data querying instead of text-based retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4474420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def file_loader(self, path, name, hash=None, domain=None):\n",
    "        ext = self.check_file_path(name)\n",
    "        ext = ext.lower()   ##Converts the extension to lowercase so that comparisons are case-insensitive (e.g., PDF → pdf)\n",
    "        if ext == 'pdf':\n",
    "            loader = PyMuPDFLoader(path, extract_images=True)\n",
    "            self.agent_avail = False\n",
    "            return loader.load()    ##Returns the extracted content using loader.load().\n",
    "\n",
    "\n",
    "        elif ext == 'docx' or ext == 'doc':\n",
    "            # loader = Docx2txtLoader(path)\n",
    "            convert_pdf = docx_to_pdf(path) #Converts the Word file to PDF using docx_to_pdf(path).\n",
    "            loader = PyMuPDFLoader(convert_pdf, extract_images=True)\n",
    "            self.agent_avail = False\n",
    "            self.page = False\n",
    "            return loader.load()\n",
    "        elif ext == 'pptx' or ext == 'ppt':\n",
    "            # loader = UnstructuredPowerPointLoader(path)\n",
    "            convert_pdf = ppt_to_pdf(path) ##Converts PowerPoint to PDF using ppt_to_pdf(path).\n",
    "            print(\"done 3\")\n",
    "            loader = PyMuPDFLoader(convert_pdf)\n",
    "            self.agent_avail = False\n",
    "            self.page = False\n",
    "            return loader.load()\n",
    "        elif ext == 'txt':\n",
    "            self.page = False\n",
    "            response = requests.get(path) ##Downloads the text file from a URL (requests.get(path)).\n",
    "            data = response.text\n",
    "            with open(f\"{self.temp_pdf_path}/temp.txt\", \"w\") as file:\n",
    "                file.write(data)  #Saves the downloaded text in a temporary file.\n",
    "            loader = TextLoader(f\"{self.temp_pdf_path}/temp.txt\") #Loads the text using TextLoader.\n",
    "            self.agent_avail = False\n",
    "            return loader.load()\n",
    "        elif ext == 'csv':\n",
    "            try:\n",
    "                self.df = pd.read_csv(path) #it read the CSV file into a Pandas DataFrame\n",
    "                self.df.to_csv(f\"{self.emb}/{domain}/{hash}.csv\", index=False) #Saves in {domain}/{hash}.csv folder.\n",
    "                self.agent_avail = True\n",
    "            except:\n",
    "                os.system(f\"mkdir {self.emb}/{domain}\") #If the folder doesn't exist, it creates the directory (os.system(f\"mkdir {self.emb}/{domain}\")).\n",
    "\n",
    "                self.df.to_csv(f\"{self.emb}/{domain}/{hash}.csv\", index=False)\n",
    "                self.agent_avail = True\n",
    "        elif ext == 'xlsx':\n",
    "            try:\n",
    "                all_sheets = pd.read_excel(path, sheet_name=None) #Reads all sheets from the Excel file.\n",
    "                sheets = all_sheets.keys()\n",
    "                os.system(f\"mkdir {self.emb}/{domain}/{hash}\")\n",
    "                for sheet_name in sheets:\n",
    "                    temp_df = pd.DataFrame(pd.read_excel(path, sheet_name=sheet_name))\n",
    "                    temp_df.to_csv(f\"{self.emb}/{domain}/{hash}/{sheet_name}.csv\", index=False)\n",
    "                self.agent_avail = True\n",
    "            except:\n",
    "                all_sheets = pd.read_excel(path, sheet_name=None)\n",
    "                sheets = all_sheets.keys()\n",
    "                os.system(f\"mkdir {self.emb}/{domain}\")\n",
    "                os.system(f\"mkdir {self.emb}/{domain}/{hash}\")\n",
    "                for sheet_name in sheets:\n",
    "                    temp_df = pd.DataFrame(pd.read_excel(path, sheet_name=sheet_name)) #Saves each sheet as a CSV file in the folder.\n",
    "                    temp_df.to_csv(f\"{self.emb}/{domain}/{hash}/{sheet_name}.csv\", index=False)\n",
    "                self.agent_avail = True\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc2341",
   "metadata": {},
   "source": [
    "# 5. text_splitter(self, texts)\n",
    "Splits long texts into smaller chunks (3,000 characters with 1,000-character overlap).\n",
    "\n",
    "\n",
    "Creates a RecursiveCharacterTextSplitter object.it splits long text into smaller parts for easier processing.\n",
    "\n",
    "chunk_size=3000 → Each text chunk will be at most 3000 characters long.\n",
    "chunk_overlap=1000 → Each chunk will overlap the next one by 1000 characters.\n",
    "\n",
    "This preserves context when splitting text, preventing loss of meaning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c9e8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_splitter(self, texts):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=3000,\n",
    "            chunk_overlap=1000)\n",
    "        return text_splitter.split_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2686e",
   "metadata": {},
   "source": [
    "# 6. embed_data(self, texts, domain, index)\n",
    "Converts text into numerical vectors using HuggingFaceEmbeddings.\n",
    "Stores these vectors in Chroma for retrieval.\n",
    "\n",
    "Connects to the ChromaDB database.ChromaDB is a vector database used for storing and retrieving embeddings.\n",
    "\n",
    "Creates a collection for storing embeddings.\n",
    "\n",
    "Converts each text chunk into a vector and stores it.\n",
    "Sets up a retriever to fetch similar text chunks when queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb13985c",
   "metadata": {},
   "outputs": [],
   "source": [
    " def embed_data(self, texts, domain, index):\n",
    "        self.persistent_client = chromadb.PersistentClient(self.emb + f\"/{domain}/\") #Creates a persistent database connection with ChromaDB.\n",
    "        collection = self.persistent_client.create_collection(name=index, metadata={\"hnsw:space\": \"cosine\"})\n",
    "        #Creates a folder inside ChromaDB to store embeddings.Uses \"cosine\" similarity for searching (compares embeddings based on angle differences).\n",
    "        collection = self.persistent_client.get_collection(index)\n",
    "        for i in texts:\n",
    "            collection.upsert(\n",
    "                documents=str(i.page_content).encode('utf-8', 'replace').decode('utf-8'), #Converts the document text (i.page_content) into a string format that avoids encoding issues.\n",
    "                embeddings=self.embeddings.embed_query(i.page_content),#create numerical representations of the text.\n",
    "                metadatas=i.metadata,\n",
    "                ids=[str(uuid.uuid1())] #Generates a unique ID for each document using uuid.uuid1().\n",
    "\n",
    "            )\n",
    "\n",
    "        langchain_chroma = Chroma(\n",
    "            client=self.persistent_client,\n",
    "            collection_name=index,\n",
    "            embedding_function=self.embeddings, )\n",
    "        self.retriever = langchain_chroma.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ea3ac",
   "metadata": {},
   "source": [
    " Connects to ChromaDB and creates/retrieves a collection.\n",
    " Loops through text chunks and converts them into embeddings.\n",
    " Stores embeddings in ChromaDB along with metadata.\n",
    " Sets up a retriever to find the top 5 most similar documents when searching.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd5645",
   "metadata": {},
   "source": [
    "# 7. load_embedings(self, domain, index)\n",
    "Loads pre-stored embeddings from the database and prepares a retriever for searching.\n",
    "This avoids re-processing the document every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b679e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def load_embedings(self, domain, index):\n",
    "        self.persistent_client = chromadb.PersistentClient(self.emb + f\"/{domain}/\")\n",
    "        collection = self.persistent_client.get_collection(index)\n",
    "        langchain_chroma = Chroma(\n",
    "            client=self.persistent_client,\n",
    "            collection_name=index,\n",
    "            embedding_function=self.embeddings, ) #Wraps the ChromaDB collection inside LangChain’s Chroma tool.\n",
    "        self.retriever = langchain_chroma.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7643a0",
   "metadata": {},
   "source": [
    "# 8. qas(self, domain=None, hash=None)\n",
    "This method initializes either:\n",
    "\n",
    "A structured data agent (for CSV/XLSX files)\n",
    "\n",
    "Loads all sheets in an Excel file.\n",
    "Uses an agent to answer queries using ChatOpenAI.\n",
    "A text-based question-answering system\n",
    "\n",
    "Uses llm to retrieve information from the embedded document.\n",
    "The prompt ensures responses are professional and stay within the document’s context.\n",
    "If a user asks for PII (Personally Identifiable Information) like names, emails, phone numbers, etc., the system replaces them with @#$%^ to protect privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd34075b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def qas(self, domain=None, hash=None):\n",
    "        temp_list = []\n",
    "        print(self.agent_avail)\n",
    "        if self.agent_avail:\n",
    "            for i in os.listdir(f\"../Embeddings/{domain}/{hash}/\"):\n",
    "                df = pd.read_csv(f\"../Embeddings/{domain}/{hash}/{i}\")\n",
    "                temp_list.append(df)\n",
    "            self.agent = create_pandas_dataframe_agent(ChatOpenAI(temperature=0, ), temp_list, verbose=True,\n",
    "                                                       agent_type=AgentType.OPENAI_FUNCTIONS, allow_dangerous_code=True)\n",
    "            print(\"code in gent\")\n",
    "        else:\n",
    "            prompt_template = \"\"\"You are a helpful and professional AI assistant called Veda. \n",
    "            You have access to a single document that has been provided to you. \n",
    "            If a user only greets you only then answer Hello! I am veda How i can assist you. \n",
    "            If there is a question after the greeting do the remaining task.\n",
    "            Your goal is to engage in a conversation with the user and answer their questions to the best of your ability using only the information contained within the given document. \n",
    "            If the user asks a question that cannot be answered based on the contents of the document, politely inform them that you do not have enough information to provide an answer.\n",
    "            If a user asks for your opinion politely decline.\n",
    "            If the question {question} asked by the user is not professional rephrase the question in a professional manner and then answer the rephrased question do not tell the user that the question has been rephrased.\n",
    "            Also Do not tell the user to be professional\n",
    "            If the rephrased question can only be answered by going out of context politely decline.\n",
    "            You should keep the conversation professional and not stray from the topic.\n",
    "            All the conversation should be witthin the provided {context}\n",
    "\n",
    "            if the user asks for the name of the document. Use {Doc_name} as the name of the document.\n",
    "\n",
    "            When a user requests any kind of PII (Personally Identifiable Information) data, such as names, addresses, phone numbers, email addresses, social security numbers, or any other information that could be used to identify a specific individual, just respond with @#$%^ without any modifications or additional information. \n",
    "            Do not attempt to generate, predict, or make up any PII data in your responses. \n",
    "            Strictly use the provided message @#$%^ whenever PII data is requested or discussed by the user.\n",
    "\n",
    "\n",
    "\n",
    "            The document you have access to is the following:\n",
    "            {context}\n",
    "            You should aim to provide concise and relevant answers, extracting key details from the document as needed to address the user's questions.\n",
    "            Feel free to quote short excerpts from the document to support your responses. \n",
    "            Remember to stay on topic and avoid making claims that are not backed up by the document. \n",
    "            If you are uncertain about something, it's better to say you're not sure rather than speculating.\n",
    "            Your conversation should be professional and natural, as if you are an intelligent and knowledgeable assistant. \n",
    "            Greet the user to begin the conversation. Let me know if you have any other questions!\n",
    "            You are also provided with a chat history {chat_history} use that history to exxpand your knowledge about the current conversation that is going on and also use that to keep the conversation helpful and professional\n",
    "            QUESTION:```{question}```\n",
    "            ANSWER:\"\"\"\n",
    "            PROMPT = PromptTemplate(\n",
    "                template=prompt_template, input_variables=[\"context\", \"question\", \"chat_history\", \"Doc_name\"]\n",
    "            )\n",
    "            chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "            self.qa = ConversationalRetrievalChain.from_llm(llm=ChatOpenAI(\n",
    "                temperature=0.5,\n",
    "                verbose=True,\n",
    "            ),\n",
    "                retriever=self.retriever,\n",
    "                chain_type=\"stuff\",\n",
    "                combine_docs_chain_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=True,\n",
    "                verbose=True, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca43e2a",
   "metadata": {},
   "source": [
    "# 9. agent_output(self, query)\n",
    "If the document is a structured file (CSV/Excel), this method runs queries on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "385687fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def agent_output(self, query):\n",
    "        return self.agent.invoke(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ae637",
   "metadata": {},
   "source": [
    "# 10. output(self, query, history, name)\n",
    "Answers user queries based on the uploaded document.\n",
    "Returns a structured response with the answer.\n",
    "This function takes a user’s question and chat history and gets an answer.then returns the answer in JSON format.\n",
    "JSON (JavaScript Object Notation) is a lightweight format for storing and exchanging data. It is used in APIs, web applications, and AI systems because it's easy to read and write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b068798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def output(self, query, history, name):\n",
    "        llm_response = self.qa.invoke({\"question\": query, \"chat_history\": history, \"Doc_name\": name})\n",
    "        json_response = {\n",
    "            \"question\": query,\n",
    "            \"answer\": llm_response['answer'],\n",
    "        }\n",
    "        return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9bdd63",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "Uploads a file (PDF, DOCX, PPT, TXT, CSV, XLSX).\n",
    "Extracts text.\n",
    "Embeds the text into a database for fast retrieval.\n",
    "Allows querying of either text-based documents or structured files.\n",
    "Provides professional AI-generated responses.\n",
    "Responses stay within the document’s context.\n",
    "Example Use Case:\n",
    "User uploads a PDF (e.g., a research paper).\n",
    "The system extracts text and creates embeddings.\n",
    "The user asks: \"What is the key conclusion of this paper?\"\n",
    "The llm retrieves relevant sections and provides an answer.\n",
    "\n",
    "\n",
    "Similarly, if a CSV file is uploaded:\n",
    "The user can ask: \"What is the average sales revenue in Q1?\"\n",
    "The llm analyzes the data and responds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
